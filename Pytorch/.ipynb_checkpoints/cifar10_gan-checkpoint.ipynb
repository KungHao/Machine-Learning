{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.0001\n",
    "LR_D = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cuda:0\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)\n",
    "device = 'cpu'\n",
    "\n",
    "#loading the dataset\n",
    "data_train = datasets.CIFAR10(root=\"C:/Users/james/python_jupyter/datasets\", download=False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "data_loader = torch.utils.data.DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(data_loader.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data_loader.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def showImg(imgs):\n",
    "    sqrtn = int(np.ceil(np.sqrt(imgs.shape[0])))\n",
    "    for index, img in enumerate(imgs):\n",
    "        plt.subplot(sqrtn, sqrtn, index+1)\n",
    "        plt.imshow(img.reshape(32, 32, 3).astype('uint8'))\n",
    "        plt.axis(False)\n",
    "    plt.show()\n",
    "# showImg(data_loader.dataset.data[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1024*3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024*3)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=3, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Generator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=3072, bias=True)\n",
      "  )\n",
      ")\n",
      "MSELoss()\n"
     ]
    }
   ],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n",
    "loss_f = nn.MSELoss().to(device)\n",
    "D_optim = torch.optim.Adam(D.parameters(), lr=LR_D)\n",
    "G_optim = torch.optim.Adam(G.parameters(), lr=LR_G)\n",
    "print(D)\n",
    "print(G)\n",
    "print(loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prob_real' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b9ca64e35cfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob_real\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prob_real' is not defined"
     ]
    }
   ],
   "source": [
    "print(prob_real.size())\n",
    "print(ones.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([64, 3])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10, 0/782, D_loss: 0.250  G_loss: 0.553\n",
      "0/10, 100/782, D_loss: 0.069  G_loss: 0.748\n",
      "0/10, 200/782, D_loss: 0.005  G_loss: 0.984\n",
      "0/10, 300/782, D_loss: 0.014  G_loss: 0.963\n",
      "0/10, 400/782, D_loss: 0.000  G_loss: 1.000\n",
      "0/10, 500/782, D_loss: 0.000  G_loss: 1.000\n",
      "0/10, 600/782, D_loss: 0.000  G_loss: 1.000\n",
      "0/10, 700/782, D_loss: 0.000  G_loss: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([16, 3])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAADnCAYAAACEyTRLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAADcUlEQVR4nO3bsW3EQAwAwaWh/lumO1AmnCXPpJcQDBYE/jW7G8B/93N6AIC/QAwBEkOASgwBKjEEqOq6e5yZV//UvLtzeoY79vscu33OV3frMgRIDAEqMQSoxBCgEkOASgwBKjEEqMQQoBJDgEoMASoxBKjEEKASQ4BKDAEqMQSoxBCgEkOASgwBKjEEqMQQoBJDgEoMASoxBKjEEKASQ4BKDAEqMQSoxBCgEkOASgwBKjEEqMQQoBJDgEoMASoxBKjEEKASQ4BKDAEqMQSoxBCgEkOASgwBKjEEqMQQoBJDgEoMASoxBKhqdvf0DADHuQwBEkOASgwBKjEEqMQQoBJDgEoMASoxBKjqunucmVf/I3t35/QMd+z3OXb7nK/u1mUIkBgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUNbt7egaA41yGAIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQ1XX3ODOv/jxld+f0DHfs9zl2+5yv7tZlCJAYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVDW7e3oGgONchgCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUNV19zgzr/48ZXfn9Ax37Pc5dvucr+7WZQiQGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlQ1u3t6BoDjXIYAiSFAJYYAlRgCVGIIUIkhQFW/DzpQwzEfSLoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 1...\n",
      "1/10, 0/782, D_loss: 0.000  G_loss: 1.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    print('start epoch {}...'.format(epoch))\n",
    "    for i, (img, label) in enumerate(data_loader):\n",
    "        batch_size = img.shape[0]\n",
    "        \n",
    "        z = torch.randn(batch_size, 100)\n",
    "        \n",
    "        real_img = img.view(-1, 1024*3)\n",
    "        fake_img = G(z)\n",
    "        \n",
    "        ones = torch.ones(batch_size, 3)\n",
    "        zeros = torch.zeros(batch_size, 3)\n",
    "        \n",
    "        #Discriminator\n",
    "        prob_real = D(real_img)\n",
    "        prob_fake = D(fake_img)\n",
    "        \n",
    "        D_loss_real = loss_f(prob_real, ones)\n",
    "        D_loss_fake = loss_f(prob_fake, zeros)\n",
    "        D_loss = (D_loss_real + D_loss_fake) / 2\n",
    "        \n",
    "        #Generator\n",
    "        G_loss = loss_f(D_loss_fake, ones)\n",
    "        \n",
    "        D_optim.zero_grad()\n",
    "        D_loss.backward(retain_graph=True)      # reusing computational graph\n",
    "        D_optim.step()\n",
    "\n",
    "        G_optim.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optim.step()\n",
    "        \n",
    "        \n",
    "        if i % 100 == 0 or i == len(data_loader):\n",
    "            print('{}/{}, {}/{}, D_loss: {:.3f}  G_loss: {:.3f}'.format(epoch, EPOCH, i, len(data_loader), D_loss.item(), G_loss.item()))\n",
    "            pass\n",
    "#     imgs_numpy = (fake_img.data.cpu().numpy()+1.0)/2.0\n",
    "    imgs_numpy = (fake_img.data.cpu().numpy())\n",
    "    showImg(imgs_numpy[:16])\n",
    "    plt.show()\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fake_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e5ae7057afdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimgs_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfake_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mshowImg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_numpy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_numpy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fake_img' is not defined"
     ]
    }
   ],
   "source": [
    "imgs_numpy = (fake_img.data.cpu().numpy())\n",
    "showImg(imgs_numpy[:16])\n",
    "plt.show()\n",
    "print(imgs_numpy[:16].shape)\n",
    "print(img.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
