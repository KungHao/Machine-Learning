{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.0001\n",
    "LR_D = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cpu\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)\n",
    "\n",
    "#loading the dataset\n",
    "data_train = datasets.CIFAR10(root=\"./datasets\", download=False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "data_loader = torch.utils.data.DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(data_loader.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data_loader.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def showImg(imgs):\n",
    "    sqrtn = int(np.ceil(np.sqrt(imgs.shape[0])))\n",
    "    for index, img in enumerate(imgs):\n",
    "        plt.subplot(sqrtn, sqrtn, index+1)\n",
    "        plt.imshow(img.reshape(32, 32, 3).astype('uint8'))\n",
    "        plt.axis(False)\n",
    "    plt.show()\n",
    "# showImg(data_loader.dataset.data[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1024*3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024*3)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=3, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Generator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=3072, bias=True)\n",
      "  )\n",
      ")\n",
      "MSELoss()\n"
     ]
    }
   ],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n",
    "loss_f = nn.MSELoss().to(device)\n",
    "D_optim = torch.optim.Adam(D.parameters(), lr=LR_D)\n",
    "G_optim = torch.optim.Adam(G.parameters(), lr=LR_G)\n",
    "print(D)\n",
    "print(G)\n",
    "print(loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3])\n",
      "torch.Size([192, 1])\n"
     ]
    }
   ],
   "source": [
    "print(prob_real.size())\n",
    "print(ones.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([64, 3])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1, 0/782, D_loss: 0.251  G_loss: 0.559\n",
      "0/1, 100/782, D_loss: 0.050  G_loss: 0.815\n",
      "0/1, 200/782, D_loss: 0.029  G_loss: 0.935\n",
      "0/1, 300/782, D_loss: 0.000  G_loss: 0.999\n",
      "0/1, 400/782, D_loss: 0.001  G_loss: 0.998\n",
      "0/1, 500/782, D_loss: 0.007  G_loss: 0.989\n",
      "0/1, 600/782, D_loss: 0.003  G_loss: 0.989\n",
      "0/1, 700/782, D_loss: 0.000  G_loss: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([16, 3])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3072 into shape (32,32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-4d2fa0c7a922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m#     imgs_numpy = (fake_img.data.cpu().numpy()+1.0)/2.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mimgs_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfake_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mshowImg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_numpy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done!!!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-81-83a4de73ce31>\u001b[0m in \u001b[0;36mshowImg\u001b[1;34m(imgs)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqrtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqrtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 3072 into shape (32,32)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHUAAABSCAYAAABqrZsyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEWUlEQVR4nO2dT2gdVRSHv5+tVchCwWZRtFCLxZCFi/YhXYkgQptFutBFutFIJRQtrgUXQjfiShCLJWLxz6IWu4qgCKLgytoX8E+rKKkgBgumKt0I1cBxMZMaHi95d17uvBkP54OBN3PvzBzex7w3HM69V2ZG4Itbmg4gyE9IdUhIdUhIdUhIdUhIdchAqZLOSPpN0qUN2iXpVUlLkr6RtD9/mEEVUp7Ut4BDm7QfBvaV2xzw+tbDCrbCQKlm9jnwxyZdjgDvWMEXwJ2SduUKMKhOjv/Uu4Ff1u0vl8eChtie4Rrqc6xv7lHSHMVPNGNjYwcmJiYy3N4vi4uL18xsvOp5OaQuA7vX7d8D/Nqvo5nNA/MAnU7Hut1uhtv7RdLPw5yX4+d3AXiifAs+CFw3s6sZrhsMycAnVdJZ4GFgp6Rl4EXgVgAzOw18CEwBS8BfwFN1BRukMVCqmR0d0G7As9kiCrZMZJQcElIdElIdElIdElIdElIdElIdElIdElIdElIdElIdElIdElIdElIdElIdkiRV0iFJP5S1vc/3aZ+VtCLpq3J7On+oQSoplQ/bgFPAoxT1SBclLZjZdz1dz5nZiRpiDCqS8qQ+CCyZ2U9m9jfwHkWtb9BSUqSm1vU+Vg67OC9pd592JM1J6krqrqysDBFukEKK1JS63g+APWb2APAJ8Ha/C5nZvJl1zKwzPl65nDVIJEXqwLpeM/vdzG6Uu28AB/KEFwxDitSLwD5J90raAcxQ1PrepGfszDTwfb4Qg6qklIiuSjoBfAxsA86Y2WVJJ4GumS0Az0maBlYpBlPN1hhzMAA1NeVODLsYjKRFM+tUPS8ySg4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ7JVSJ6m6RzZfsFSXtyBxqkkzLf71qJ6GFgEjgqabKn2zHgTzO7D3gFeDl3oEE6uUpEj/Bfsdl54BFJ/QrWghGQq0T0Zh8zWwWuA3flCDCoTsosoikloknTw66fGha4sdEU7g2xE7jWdBA93D/MSSlSU6Z+XeuzLGk7cAd9ZvNePzWspO4w9Td10bZ4oIhpmPOylIiW+0+Wnx8HPrVYRK4xcpWIvgm8K2mJ4gmdqTPoYHMaKxGVNFf+HLeCtsUDw8fUmNSgPiJN6JDapbYtxdi2UfG1rNBlZrVtFC9WV4C9wA7ga2Cyp88zwOny8wzFiPQm45kFXqvze+m530PAfuDSBu1TwEcUuYCDwIVB16z7SW1birF1o+KthhW66pbathRjtlHxI6TyCl11S82WYsxEtlHxI6Ty91O31CopRjZLMY4qnhaOik9eoWuNuqW2LcX4fxwVX32FrhG83U0BP1K8db5QHjsJTJefbwfep1iB6ktgb8PxvARcpngz/gyYqDmes8BV4B+Kp/IYcBw4XraLokjhCvAt0Bl0zcgoOSQySg4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ4JqQ75F6gQncuTznR2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    print('start epoch {}...'.format(epoch))\n",
    "    for i, (img, label) in enumerate(data_loader):\n",
    "        batch_size = img.shape[0]\n",
    "        \n",
    "        z = torch.randn(batch_size, 100)\n",
    "        \n",
    "        real_img = img.view(-1, 1024*3)\n",
    "        fake_img = G(z)\n",
    "        \n",
    "        ones = torch.ones(batch_size, 3)\n",
    "        zeros = torch.zeros(batch_size, 3)\n",
    "        \n",
    "        #Discriminator\n",
    "        prob_real = D(real_img)\n",
    "        prob_fake = D(fake_img)\n",
    "        \n",
    "        D_loss_real = loss_f(prob_real, ones)\n",
    "        D_loss_fake = loss_f(prob_fake, zeros)\n",
    "        D_loss = (D_loss_real + D_loss_fake) / 2\n",
    "        \n",
    "        #Generator\n",
    "        G_loss = loss_f(D_loss_fake, ones)\n",
    "        \n",
    "        D_optim.zero_grad()\n",
    "        D_loss.backward(retain_graph=True)      # reusing computational graph\n",
    "        D_optim.step()\n",
    "\n",
    "        G_optim.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optim.step()\n",
    "        \n",
    "        \n",
    "        if i % 100 == 0 or i == len(data_loader):\n",
    "            print('{}/{}, {}/{}, D_loss: {:.3f}  G_loss: {:.3f}'.format(epoch, EPOCH, i, len(data_loader), D_loss.item(), G_loss.item()))\n",
    "            pass\n",
    "#     imgs_numpy = (fake_img.data.cpu().numpy()+1.0)/2.0\n",
    "    imgs_numpy = (fake_img.data.cpu().numpy())\n",
    "    showImg(imgs_numpy[:16])\n",
    "    plt.show()\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAADnCAYAAACEyTRLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADcUlEQVR4nO3bsW3EQAwAwaWh/lumO1AmnCXPpJcQDBYE/jW7G8B/93N6AIC/QAwBEkOASgwBKjEEqOq6e5yZV//UvLtzeoY79vscu33OV3frMgRIDAEqMQSoxBCgEkOASgwBKjEEqMQQoBJDgEoMASoxBKjEEKASQ4BKDAEqMQSoxBCgEkOASgwBKjEEqMQQoBJDgEoMASoxBKjEEKASQ4BKDAEqMQSoxBCgEkOASgwBKjEEqMQQoBJDgEoMASoxBKjEEKASQ4BKDAEqMQSoxBCgEkOASgwBKjEEqMQQoBJDgEoMASoxBKhqdvf0DADHuQwBEkOASgwBKjEEqMQQoBJDgEoMASoxBKjqunucmVf/I3t35/QMd+z3OXb7nK/u1mUIkBgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUNbt7egaA41yGAIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQ1XX3ODOv/jxld+f0DHfs9zl2+5yv7tZlCJAYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVDW7e3oGgONchgCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUNV19zgzr/48ZXfn9Ax37Pc5dvucr+7WZQiQGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlRiCFCJIUAlhgCVGAJUYghQiSFAJYYAlRgCVGIIUIkhQCWGAJUYAlQ1u3t6BoDjXIYAiSFAJYYAlRgCVGIIUIkhQFW/DzpQwzEfSLoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3072)\n",
      "torch.Size([16, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "imgs_numpy = (fake_img.data.cpu().numpy())\n",
    "showImg(imgs_numpy[:16])\n",
    "plt.show()\n",
    "print(imgs_numpy[:16].shape)\n",
    "print(img.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
